# hse_hw_python_final
Финальная работа по питону by **andrekur**

## Установка
```
git clone https://github.com/andrekur/hse_hw_python_final.git
cd hse_hw_python_final
mv env.example .env
sudo docker-compose build
sudo docker-compose up
```

В ```.env``` файле прописаны все порты и конфигурация проекта.

## Витрины
Каждая витрина представлена отдельным файлом по пути: ```./airflow/spark_scripts/calc_{название_витрины}.py```

Для каждой витрины сформирован отдельный даг по пути: <br>```./airflow/dags/{название_витрины}.py```

### `dm_user_stats`
**Описание:** витрина по тратам пользователей с разбивкой по статусам ```('Paid', 'Delivery', 'Completed')```

**Показатели:**
- Кол. заказов
- Потрачено всего
- Средний чек
- Статус

**Предназначение** - анализ пользовательской активности покупок <br><br>

### `dm_product_stats`
**Описание:** витрина по статистике продажи/остаткам товаров

**Показатели:**
- Выручка по продукту
- Продано
- Осталось

**Предназначение** - анализ рентабельности продукта(продано/осталось и тд) и выручки по нему<br><br>

### `dm_order_stats`
**Описание:** витрина по состоянию заказов (на каждый день создается своя таблица), сколько в каком статусе

**Показатели:**
- Статус заказа ```('Paid', 'Delivery', 'Completed')```
- Кол. в данном статусе

**Предназначение** - анализ состояния и кол. заказов в день в каждом статусе<br><br>

### `dm_category_stats`
**Описание:** витрина по статистики продажи/остаткам по категориям

**Показатели:**
- Прибыль категории
- Кол. проданных товаров в категории

**Предназначение** - анализ рентабельности категорий <br><br>

## Репликация из Postgresql в MySQL
Скрипт для репликации представлен по пути: <br>
```./airflow/spark_scripts/replicate_table.py```

## Генерация данных для целевой БД
Скрипт для репликации представлен по пути: <br>
```./data_generators/db_data_gen/main.py```

Даг для репликации представлен по пути: <br>```./airflow/dags/replica.py```

## Контейнера
1. **PostgreSQL** - целевая БД
2. **MySQL** - БД в которую реплецируем из целевой
3. **data_generator** - генерация данных для целевой БД
4. **airflow-init** - первичный запуск airflow и настройка
5. **airflow-webserver** - админка для airflow
6. **airflow-scheduler** - запуск по расписанию для airflow
7. **spark** - мастер для спарка
8. **spark-worker** - воркеры для спарка